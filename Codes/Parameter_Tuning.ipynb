{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-31T12:37:35.383766200Z",
     "start_time": "2024-01-31T12:37:31.174560900Z"
    }
   },
   "outputs": [],
   "source": [
    "from Esemble import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import optuna\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_for_DNN = pd.read_csv('../Database/train_for_DNN.csv', index_col='ID')\n",
    "X_for_DNN = train_for_DNN.drop(columns=['대출등급'])\n",
    "y_for_DNN = train_for_DNN['대출등급']\n",
    "X_train_DNN, X_val_DNN, y_train_DNN, y_val_DNN = train_test_split(X_for_DNN, y_for_DNN, test_size=0.2, random_state=42)\n",
    "Tuning = False\n",
    "E = Esemble(4, X_train_DNN, X_val_DNN, y_train_DNN, y_val_DNN, 100, Tuning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T11:28:53.368133100Z",
     "start_time": "2024-01-31T11:28:53.173289700Z"
    }
   },
   "id": "a0ed409de64e23a8",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-31 21:37:40,172] A new study created in memory with name: no-name-789466c9-b8d9-4b80-bf8e-4e13dfa5af20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "epoch 0  | loss: 2.02273 | val_0_logloss: 1.77256 |  0:00:10s\n",
      "epoch 1  | loss: 1.35234 | val_0_logloss: 1.50638 |  0:00:19s\n",
      "epoch 2  | loss: 1.265   | val_0_logloss: 1.21117 |  0:00:28s\n",
      "epoch 3  | loss: 1.13812 | val_0_logloss: 1.36361 |  0:00:38s\n",
      "epoch 4  | loss: 1.03591 | val_0_logloss: 1.49085 |  0:00:47s\n",
      "epoch 5  | loss: 0.96664 | val_0_logloss: 1.9799  |  0:00:56s\n",
      "epoch 6  | loss: 0.8712  | val_0_logloss: 1.51788 |  0:01:06s\n",
      "epoch 7  | loss: 0.80453 | val_0_logloss: 1.12527 |  0:01:16s\n",
      "epoch 8  | loss: 0.78754 | val_0_logloss: 1.06954 |  0:01:26s\n",
      "epoch 9  | loss: 0.75484 | val_0_logloss: 2.79099 |  0:01:37s\n",
      "epoch 10 | loss: 0.68195 | val_0_logloss: 1.00515 |  0:01:47s\n",
      "epoch 11 | loss: 0.6759  | val_0_logloss: 1.52641 |  0:01:56s\n",
      "epoch 12 | loss: 0.64827 | val_0_logloss: 0.68719 |  0:02:06s\n",
      "epoch 13 | loss: 0.63116 | val_0_logloss: 1.6585  |  0:02:15s\n",
      "epoch 14 | loss: 0.63465 | val_0_logloss: 0.92879 |  0:02:25s\n",
      "epoch 15 | loss: 0.63006 | val_0_logloss: 0.69941 |  0:02:34s\n",
      "epoch 16 | loss: 0.59578 | val_0_logloss: 0.67726 |  0:02:44s\n",
      "epoch 17 | loss: 0.59443 | val_0_logloss: 1.20835 |  0:02:53s\n",
      "epoch 18 | loss: 0.59255 | val_0_logloss: 1.02806 |  0:03:02s\n",
      "epoch 19 | loss: 0.5664  | val_0_logloss: 0.59273 |  0:03:12s\n",
      "epoch 20 | loss: 0.58744 | val_0_logloss: 0.91181 |  0:03:21s\n",
      "epoch 21 | loss: 0.56824 | val_0_logloss: 0.88731 |  0:03:30s\n",
      "epoch 22 | loss: 0.55782 | val_0_logloss: 1.09327 |  0:03:40s\n",
      "epoch 23 | loss: 0.58103 | val_0_logloss: 0.68202 |  0:03:49s\n",
      "epoch 24 | loss: 0.56486 | val_0_logloss: 0.65983 |  0:03:58s\n",
      "epoch 25 | loss: 0.55537 | val_0_logloss: 0.68249 |  0:04:08s\n",
      "epoch 26 | loss: 0.56829 | val_0_logloss: 0.69507 |  0:04:17s\n",
      "epoch 27 | loss: 0.56036 | val_0_logloss: 1.77212 |  0:04:27s\n",
      "epoch 28 | loss: 0.56943 | val_0_logloss: 0.59608 |  0:04:36s\n",
      "epoch 29 | loss: 0.56099 | val_0_logloss: 0.71286 |  0:04:45s\n",
      "epoch 30 | loss: 0.55749 | val_0_logloss: 0.73181 |  0:04:55s\n",
      "epoch 31 | loss: 0.54043 | val_0_logloss: 0.56612 |  0:05:04s\n",
      "epoch 32 | loss: 0.53144 | val_0_logloss: 0.69006 |  0:05:13s\n",
      "epoch 33 | loss: 0.54819 | val_0_logloss: 0.61976 |  0:05:23s\n",
      "epoch 34 | loss: 0.55712 | val_0_logloss: 1.07552 |  0:05:32s\n",
      "epoch 35 | loss: 0.55561 | val_0_logloss: 0.63872 |  0:05:42s\n",
      "epoch 36 | loss: 0.55013 | val_0_logloss: 0.59637 |  0:05:51s\n",
      "epoch 37 | loss: 0.55315 | val_0_logloss: 1.24966 |  0:06:00s\n",
      "epoch 38 | loss: 0.54744 | val_0_logloss: 0.81019 |  0:06:10s\n",
      "epoch 39 | loss: 0.53544 | val_0_logloss: 0.77288 |  0:06:19s\n",
      "epoch 40 | loss: 0.543   | val_0_logloss: 0.65445 |  0:06:28s\n",
      "epoch 41 | loss: 0.55405 | val_0_logloss: 0.77652 |  0:06:38s\n",
      "epoch 42 | loss: 0.54072 | val_0_logloss: 0.6032  |  0:06:47s\n",
      "epoch 43 | loss: 0.53517 | val_0_logloss: 1.39453 |  0:06:57s\n",
      "epoch 44 | loss: 0.54286 | val_0_logloss: 0.68537 |  0:07:06s\n",
      "epoch 45 | loss: 0.54594 | val_0_logloss: 0.89062 |  0:07:15s\n",
      "epoch 46 | loss: 0.53515 | val_0_logloss: 0.67967 |  0:07:25s\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 31 and best_val_0_logloss = 0.56612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-31 21:45:12,656] Trial 0 finished with value: 0.8005607767796874 and parameters: {'n_d': 27, 'n_a': 28, 'n_steps': 12, 'gamma': 1.3172088060841471}. Best is trial 0 with value: 0.8005607767796874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabnet Accuracy: 0.8005607767796874\n",
      "cuda\n",
      "epoch 0  | loss: 2.60332 | val_0_logloss: 1.79555 |  0:00:17s\n",
      "epoch 1  | loss: 0.98526 | val_0_logloss: 1.57232 |  0:00:35s\n",
      "epoch 2  | loss: 0.74943 | val_0_logloss: 1.15077 |  0:00:53s\n",
      "epoch 3  | loss: 0.63511 | val_0_logloss: 0.96605 |  0:01:11s\n",
      "epoch 4  | loss: 0.55756 | val_0_logloss: 1.04687 |  0:01:29s\n",
      "epoch 5  | loss: 0.52657 | val_0_logloss: 0.56105 |  0:01:47s\n",
      "epoch 6  | loss: 0.50443 | val_0_logloss: 0.85113 |  0:02:05s\n",
      "epoch 7  | loss: 0.47254 | val_0_logloss: 0.64271 |  0:02:23s\n",
      "epoch 8  | loss: 0.4616  | val_0_logloss: 0.54467 |  0:02:40s\n",
      "epoch 9  | loss: 0.43424 | val_0_logloss: 0.62235 |  0:02:58s\n",
      "epoch 10 | loss: 0.43238 | val_0_logloss: 0.68638 |  0:03:16s\n",
      "epoch 11 | loss: 0.4198  | val_0_logloss: 0.69526 |  0:03:34s\n",
      "epoch 12 | loss: 0.40593 | val_0_logloss: 0.65644 |  0:03:52s\n",
      "epoch 13 | loss: 0.41284 | val_0_logloss: 0.65529 |  0:04:09s\n",
      "epoch 14 | loss: 0.39684 | val_0_logloss: 0.66142 |  0:04:27s\n",
      "epoch 15 | loss: 0.39283 | val_0_logloss: 0.63503 |  0:04:45s\n",
      "epoch 16 | loss: 0.37619 | val_0_logloss: 0.8824  |  0:05:03s\n",
      "epoch 17 | loss: 0.37073 | val_0_logloss: 0.55815 |  0:05:20s\n",
      "epoch 18 | loss: 0.3684  | val_0_logloss: 0.56534 |  0:05:38s\n",
      "epoch 19 | loss: 0.36729 | val_0_logloss: 0.79629 |  0:05:55s\n",
      "epoch 20 | loss: 0.37129 | val_0_logloss: 0.73158 |  0:06:13s\n",
      "epoch 21 | loss: 0.35922 | val_0_logloss: 0.61217 |  0:06:31s\n",
      "epoch 22 | loss: 0.35682 | val_0_logloss: 0.58049 |  0:06:49s\n",
      "epoch 23 | loss: 0.34856 | val_0_logloss: 0.63875 |  0:07:07s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 8 and best_val_0_logloss = 0.54467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-31 21:52:32,898] Trial 1 finished with value: 0.7951607040864012 and parameters: {'n_d': 32, 'n_a': 36, 'n_steps': 26, 'gamma': 0.9641302855392244}. Best is trial 0 with value: 0.8005607767796874.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabnet Accuracy: 0.7951607040864012\n",
      "cuda\n",
      "epoch 0  | loss: 2.70757 | val_0_logloss: 2.22344 |  0:00:14s\n",
      "epoch 1  | loss: 1.6328  | val_0_logloss: 1.53713 |  0:00:29s\n",
      "epoch 2  | loss: 1.43171 | val_0_logloss: 1.6521  |  0:00:44s\n",
      "epoch 3  | loss: 1.22679 | val_0_logloss: 1.75861 |  0:00:58s\n",
      "epoch 4  | loss: 1.06927 | val_0_logloss: 1.28349 |  0:01:13s\n",
      "epoch 5  | loss: 0.99578 | val_0_logloss: 1.48221 |  0:01:28s\n",
      "epoch 6  | loss: 0.99096 | val_0_logloss: 1.2504  |  0:01:43s\n",
      "epoch 7  | loss: 0.9539  | val_0_logloss: 1.11395 |  0:01:58s\n",
      "epoch 8  | loss: 0.90959 | val_0_logloss: 1.8119  |  0:02:12s\n",
      "epoch 9  | loss: 0.94285 | val_0_logloss: 1.49462 |  0:02:27s\n",
      "epoch 10 | loss: 0.90686 | val_0_logloss: 0.9087  |  0:02:42s\n",
      "epoch 11 | loss: 0.88188 | val_0_logloss: 0.94368 |  0:02:56s\n",
      "epoch 12 | loss: 0.89685 | val_0_logloss: 0.85243 |  0:03:11s\n",
      "epoch 13 | loss: 0.83796 | val_0_logloss: 1.31707 |  0:03:26s\n",
      "epoch 14 | loss: 0.84265 | val_0_logloss: 0.84742 |  0:03:40s\n",
      "epoch 15 | loss: 0.81931 | val_0_logloss: 0.9495  |  0:03:55s\n",
      "epoch 16 | loss: 0.74059 | val_0_logloss: 0.80856 |  0:04:10s\n",
      "epoch 17 | loss: 0.73293 | val_0_logloss: 1.5203  |  0:04:25s\n",
      "epoch 18 | loss: 0.73203 | val_0_logloss: 0.69041 |  0:04:40s\n",
      "epoch 19 | loss: 0.69482 | val_0_logloss: 0.8814  |  0:04:54s\n",
      "epoch 20 | loss: 0.68365 | val_0_logloss: 0.78312 |  0:05:09s\n",
      "epoch 21 | loss: 0.6589  | val_0_logloss: 0.84666 |  0:05:24s\n",
      "epoch 22 | loss: 0.66809 | val_0_logloss: 1.03719 |  0:05:38s\n",
      "epoch 23 | loss: 0.66484 | val_0_logloss: 0.87795 |  0:05:53s\n",
      "epoch 24 | loss: 0.63911 | val_0_logloss: 0.71837 |  0:06:08s\n",
      "epoch 25 | loss: 0.63024 | val_0_logloss: 0.98384 |  0:06:22s\n",
      "epoch 26 | loss: 0.65064 | val_0_logloss: 0.8857  |  0:06:37s\n",
      "epoch 27 | loss: 0.64315 | val_0_logloss: 0.94455 |  0:06:52s\n",
      "epoch 28 | loss: 0.63137 | val_0_logloss: 1.72513 |  0:07:06s\n",
      "epoch 29 | loss: 0.61496 | val_0_logloss: 1.09152 |  0:07:21s\n",
      "epoch 30 | loss: 0.62674 | val_0_logloss: 0.90089 |  0:07:36s\n",
      "epoch 31 | loss: 0.59977 | val_0_logloss: 1.57209 |  0:07:50s\n",
      "epoch 32 | loss: 0.60619 | val_0_logloss: 0.6522  |  0:08:05s\n",
      "epoch 33 | loss: 0.58943 | val_0_logloss: 0.86523 |  0:08:20s\n",
      "epoch 34 | loss: 0.60466 | val_0_logloss: 1.06871 |  0:08:34s\n",
      "epoch 35 | loss: 0.59932 | val_0_logloss: 0.81281 |  0:08:49s\n",
      "epoch 36 | loss: 0.58052 | val_0_logloss: 0.65775 |  0:09:04s\n",
      "epoch 37 | loss: 0.57372 | val_0_logloss: 0.65939 |  0:09:18s\n",
      "epoch 38 | loss: 0.57624 | val_0_logloss: 0.73629 |  0:09:33s\n",
      "epoch 39 | loss: 0.68552 | val_0_logloss: 1.66124 |  0:09:48s\n",
      "epoch 40 | loss: 0.61273 | val_0_logloss: 0.81252 |  0:10:03s\n",
      "epoch 41 | loss: 0.58213 | val_0_logloss: 0.69833 |  0:10:17s\n",
      "epoch 42 | loss: 0.56964 | val_0_logloss: 0.61554 |  0:10:32s\n",
      "epoch 43 | loss: 0.55788 | val_0_logloss: 0.76622 |  0:10:47s\n",
      "epoch 44 | loss: 0.55744 | val_0_logloss: 0.78144 |  0:11:01s\n",
      "epoch 45 | loss: 0.55746 | val_0_logloss: 0.89217 |  0:11:16s\n",
      "epoch 46 | loss: 0.54976 | val_0_logloss: 1.17752 |  0:11:31s\n",
      "epoch 47 | loss: 0.54225 | val_0_logloss: 0.66322 |  0:11:45s\n",
      "epoch 48 | loss: 0.52348 | val_0_logloss: 1.25224 |  0:12:00s\n",
      "epoch 49 | loss: 0.51961 | val_0_logloss: 0.53096 |  0:12:15s\n",
      "epoch 50 | loss: 0.5342  | val_0_logloss: 0.77371 |  0:12:29s\n",
      "epoch 51 | loss: 0.52837 | val_0_logloss: 0.83373 |  0:12:44s\n",
      "epoch 52 | loss: 0.53828 | val_0_logloss: 0.71349 |  0:12:59s\n",
      "epoch 53 | loss: 0.52711 | val_0_logloss: 0.58963 |  0:13:14s\n",
      "epoch 54 | loss: 0.53028 | val_0_logloss: 0.7731  |  0:13:28s\n",
      "epoch 55 | loss: 0.53098 | val_0_logloss: 0.62061 |  0:13:43s\n",
      "epoch 56 | loss: 0.50643 | val_0_logloss: 0.6832  |  0:13:58s\n",
      "epoch 57 | loss: 0.51036 | val_0_logloss: 0.95597 |  0:14:12s\n",
      "epoch 58 | loss: 0.50121 | val_0_logloss: 0.69285 |  0:14:27s\n",
      "epoch 59 | loss: 0.5083  | val_0_logloss: 0.57867 |  0:14:41s\n",
      "epoch 60 | loss: 0.51219 | val_0_logloss: 0.53826 |  0:14:56s\n",
      "epoch 61 | loss: 0.50908 | val_0_logloss: 0.67082 |  0:15:11s\n",
      "epoch 62 | loss: 0.50261 | val_0_logloss: 0.69465 |  0:15:25s\n",
      "epoch 63 | loss: 0.4821  | val_0_logloss: 0.55581 |  0:15:40s\n",
      "epoch 64 | loss: 0.48396 | val_0_logloss: 0.58645 |  0:15:55s\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 49 and best_val_0_logloss = 0.53096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-31 22:08:38,946] Trial 2 finished with value: 0.8064281634560465 and parameters: {'n_d': 30, 'n_a': 21, 'n_steps': 21, 'gamma': 1.8005656499864906}. Best is trial 2 with value: 0.8064281634560465.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabnet Accuracy: 0.8064281634560465\n",
      "cuda\n",
      "epoch 0  | loss: 3.3521  | val_0_logloss: 2.641   |  0:00:11s\n",
      "epoch 1  | loss: 2.11946 | val_0_logloss: 1.72302 |  0:00:23s\n",
      "epoch 2  | loss: 1.52397 | val_0_logloss: 1.7766  |  0:00:35s\n",
      "epoch 3  | loss: 1.42108 | val_0_logloss: 1.33791 |  0:00:46s\n",
      "epoch 4  | loss: 1.34598 | val_0_logloss: 1.33805 |  0:00:58s\n",
      "epoch 5  | loss: 1.26536 | val_0_logloss: 1.59281 |  0:01:10s\n",
      "epoch 6  | loss: 1.18331 | val_0_logloss: 1.71276 |  0:01:22s\n",
      "epoch 7  | loss: 1.09633 | val_0_logloss: 1.43624 |  0:01:34s\n",
      "epoch 8  | loss: 1.03197 | val_0_logloss: 2.81724 |  0:01:45s\n",
      "epoch 9  | loss: 1.00842 | val_0_logloss: 1.00194 |  0:01:57s\n",
      "epoch 10 | loss: 0.95632 | val_0_logloss: 0.95783 |  0:02:09s\n",
      "epoch 11 | loss: 0.95188 | val_0_logloss: 1.13063 |  0:02:21s\n",
      "epoch 12 | loss: 0.94935 | val_0_logloss: 1.3083  |  0:02:32s\n",
      "epoch 13 | loss: 0.92844 | val_0_logloss: 0.97848 |  0:02:44s\n",
      "epoch 14 | loss: 0.86024 | val_0_logloss: 0.99451 |  0:02:56s\n",
      "epoch 15 | loss: 0.83744 | val_0_logloss: 1.35698 |  0:03:08s\n",
      "epoch 16 | loss: 0.83306 | val_0_logloss: 1.90279 |  0:03:20s\n",
      "epoch 17 | loss: 0.82661 | val_0_logloss: 1.43494 |  0:03:31s\n",
      "epoch 18 | loss: 0.81037 | val_0_logloss: 0.9654  |  0:03:43s\n",
      "epoch 19 | loss: 0.80717 | val_0_logloss: 2.27458 |  0:03:55s\n",
      "epoch 20 | loss: 0.78547 | val_0_logloss: 1.60158 |  0:04:07s\n",
      "epoch 21 | loss: 0.76942 | val_0_logloss: 0.86598 |  0:04:18s\n",
      "epoch 22 | loss: 0.748   | val_0_logloss: 1.85279 |  0:04:30s\n",
      "epoch 23 | loss: 0.79035 | val_0_logloss: 0.90727 |  0:04:42s\n",
      "epoch 24 | loss: 0.76115 | val_0_logloss: 0.75981 |  0:04:53s\n",
      "epoch 25 | loss: 0.75065 | val_0_logloss: 1.04841 |  0:05:05s\n",
      "epoch 26 | loss: 0.73271 | val_0_logloss: 0.80107 |  0:05:17s\n",
      "epoch 27 | loss: 0.73889 | val_0_logloss: 0.87792 |  0:05:28s\n",
      "epoch 28 | loss: 0.73522 | val_0_logloss: 0.75251 |  0:05:40s\n",
      "epoch 29 | loss: 0.72948 | val_0_logloss: 0.75272 |  0:05:52s\n",
      "epoch 30 | loss: 0.71993 | val_0_logloss: 0.81159 |  0:06:04s\n",
      "epoch 31 | loss: 0.74193 | val_0_logloss: 2.27297 |  0:06:16s\n",
      "epoch 32 | loss: 0.72394 | val_0_logloss: 1.4864  |  0:06:28s\n",
      "epoch 33 | loss: 0.71812 | val_0_logloss: 0.83752 |  0:06:39s\n",
      "epoch 34 | loss: 0.70874 | val_0_logloss: 0.76727 |  0:06:51s\n",
      "epoch 35 | loss: 0.70076 | val_0_logloss: 1.88429 |  0:07:03s\n",
      "epoch 36 | loss: 0.74567 | val_0_logloss: 1.23397 |  0:07:15s\n",
      "epoch 37 | loss: 0.70866 | val_0_logloss: 0.77668 |  0:07:27s\n",
      "epoch 38 | loss: 0.69617 | val_0_logloss: 1.08893 |  0:07:39s\n",
      "epoch 39 | loss: 0.69085 | val_0_logloss: 0.70526 |  0:07:50s\n",
      "epoch 40 | loss: 0.68305 | val_0_logloss: 0.788   |  0:08:02s\n",
      "epoch 41 | loss: 0.67199 | val_0_logloss: 0.71938 |  0:08:14s\n",
      "epoch 42 | loss: 0.66961 | val_0_logloss: 1.25018 |  0:08:26s\n",
      "epoch 43 | loss: 0.66554 | val_0_logloss: 0.69922 |  0:08:38s\n",
      "epoch 44 | loss: 0.66404 | val_0_logloss: 1.28151 |  0:08:49s\n",
      "epoch 45 | loss: 0.66205 | val_0_logloss: 4.10851 |  0:09:01s\n",
      "epoch 46 | loss: 0.6672  | val_0_logloss: 0.84    |  0:09:13s\n",
      "epoch 47 | loss: 0.66646 | val_0_logloss: 1.0332  |  0:09:25s\n",
      "epoch 48 | loss: 0.66666 | val_0_logloss: 0.64962 |  0:09:37s\n",
      "epoch 49 | loss: 0.65    | val_0_logloss: 3.07316 |  0:09:49s\n",
      "epoch 50 | loss: 0.65828 | val_0_logloss: 1.18732 |  0:10:00s\n",
      "epoch 51 | loss: 0.67042 | val_0_logloss: 1.30249 |  0:10:13s\n",
      "epoch 52 | loss: 0.65673 | val_0_logloss: 0.84642 |  0:10:24s\n",
      "epoch 53 | loss: 0.65445 | val_0_logloss: 0.74175 |  0:10:36s\n",
      "epoch 54 | loss: 0.64027 | val_0_logloss: 0.77819 |  0:10:48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-31 22:19:32,203] Trial 3 failed with parameters: {'n_d': 51, 'n_a': 36, 'n_steps': 16, 'gamma': 1.3280611175388226} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\Documents\\GitHub\\Customer_Loan_Rate_Classification\\Codes\\Esemble.py\", line 198, in objective\n",
      "    accuracy = self.TabNet(params)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\Documents\\GitHub\\Customer_Loan_Rate_Classification\\Codes\\Esemble.py\", line 88, in TabNet\n",
      "    bst.fit(\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 258, in fit\n",
      "    self._train_epoch(train_dataloader)\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 489, in _train_epoch\n",
      "    batch_logs = self._train_batch(X, y)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 527, in _train_batch\n",
      "    output, M_loss = self.network(X)\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 616, in forward\n",
      "    return self.tabnet(x)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 492, in forward\n",
      "    steps_output, M_loss = self.encoder(x)\n",
      "                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 181, in forward\n",
      "    out = self.feat_transformers[step](masked_x)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 737, in forward\n",
      "    x = self.shared(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 774, in forward\n",
      "    x = self.glu_layers[0](x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 804, in forward\n",
      "    x = self.bn(x)\n",
      "        ^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 36, in forward\n",
      "    res = [self.bn(x_) for x_ in chunks]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 36, in <listcomp>\n",
      "    res = [self.bn(x_) for x_ in chunks]\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 171, in forward\n",
      "    return F.batch_norm(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\asas4\\anaconda3\\envs\\python_311\\Lib\\site-packages\\torch\\nn\\functional.py\", line 2478, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-31 22:19:32,208] Trial 3 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if Tuning:\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(E.objective, n_trials=10)\n",
    "\n",
    "    print('Number of finished trials:', len(study.trials))\n",
    "    print('Best trial:', study.best_trial.params)\n",
    "\n",
    "if not Tuning:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    params = {\n",
    "        'verbose': True,\n",
    "        'device_name': device,\n",
    "        'cat_dims': [2, 11, 4, 12],\n",
    "        'cat_idxs': [i for i in range(7, 11)],\n",
    "    \n",
    "        'n_d': 25,  # Decision 단계의 특성 차원\n",
    "        'n_a': 20,  # Attention 단계의 특성 차원\n",
    "        'n_steps': 15,  # Attention 단계의 반복 횟수\n",
    "        'gamma': 0.8030822637759606,  # Regularization 강도\n",
    "    }\n",
    "    \n",
    "    proba3 = E.TabNet(params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T13:19:32.532058900Z",
     "start_time": "2024-01-31T12:37:40.174142800Z"
    }
   },
   "id": "2d31116c1387cf5e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51d17fab585e72a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
